{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importing necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "# Define the model name and torch device\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Initialize quantum registers and classical re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Initialize cluster centroids randomly or usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Encode classical data points into quantum states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set maximum number of iterations and converge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Repeat until convergence or maximum iteration...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Step                                        Description\n",
       "0     1   Initialize quantum registers and classical re...\n",
       "1     2   Initialize cluster centroids randomly or usin...\n",
       "2     3   Encode classical data points into quantum states\n",
       "3     4   Set maximum number of iterations and converge...\n",
       "4     5   Repeat until convergence or maximum iteration..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('converted.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Initialize quantum registers and classical registers',\n",
       " ' Initialize cluster centroids randomly or using a deterministic method',\n",
       " ' Encode classical data points into quantum states',\n",
       " ' Set maximum number of iterations and convergence threshold',\n",
       " ' Repeat until convergence or maximum iterations reached',\n",
       " ' Assign each data point to the nearest cluster centroid',\n",
       " ' Update cluster centroids',\n",
       " ' Check for convergence',\n",
       " ' Extract final cluster centroids from quantum registers',\n",
       " ' Decode quantum cluster centroids to obtain classical representations',\n",
       " ' Evaluate clustering quality using metrics such as within-cluster sum of squares',\n",
       " ' Output the final cluster centroids and evaluation results']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i want to iterate all the elements of df to list\n",
    "df_list = df[\" Description\"].values.tolist()\n",
    "df_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/adarshgowdaa/pegasus-paraphrase/blob/main/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text, num_return_sequences):\n",
    "    batch = tokenizer.prepare_seq2seq_batch(\n",
    "        [input_text], truncation=True, padding='longest', max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch, max_length=60, num_beams=10,\n",
    "                                num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4047: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4047: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['Initialize classical and quantum registers.',\n",
       "        'Contribute quantum and classical registers.',\n",
       "        'Initialize classical and quantum register.',\n",
       "        'Contribute classical and quantum registers.',\n",
       "        'Classical and quantum registers should be created.',\n",
       "        'Contribute quantum and classical register.',\n",
       "        'The classical and quantum register should be created.',\n",
       "        'The quantum and classical registers should be created.',\n",
       "        'The classical and quantum registers should be created.',\n",
       "        'The quantum and classical register should be created.'],\n",
       "       ['Use a deterministic method to create cluster centroids.',\n",
       "        'Use a deterministic method to set up cluster centroids.',\n",
       "        'cluster centroids can be set randomly or using a deterministic method.',\n",
       "        'cluster centroids can be used using a deterministic method.',\n",
       "        'cluster centroids can be randomly or using a deterministic method.',\n",
       "        'cluster centroids can be random or deterministic.',\n",
       "        'cluster centroids can be used using a deterministic method or randomly.',\n",
       "        'cluster centroids can be random or a deterministic method.',\n",
       "        'cluster centroids can be randomly or deterministic.',\n",
       "        'cluster centroids can be set randomly or using a method.'],\n",
       "       ['Classical data points should be converted into quantum states.',\n",
       "        'Classical data points can be converted into quantum states.',\n",
       "        'Contribute classical data points to quantum states.',\n",
       "        'Classical data points should be converted to quantum states.',\n",
       "        'Classical data points can be converted to quantum states.',\n",
       "        'Classical data points should be translated into quantum states.',\n",
       "        'Contribute classical data points into quantum states.',\n",
       "        'Represent classical data points in quantum states.',\n",
       "        'Encode classical data points into quantum states.',\n",
       "        'Encode classical data points.'],\n",
       "       ['The maximum number of iterations and convergence threshold should be set.',\n",
       "        'The maximum number of iteration and convergence threshold should be set.',\n",
       "        'The maximum number of iterations and convergence threshold can be set.',\n",
       "        'The maximum number of iteration and convergence threshold can be set.',\n",
       "        'The maximum number and convergence threshold should be set.',\n",
       "        'The maximum number of iterations and the convergence threshold should be set.',\n",
       "        'There should be a maximum number of iterations and a convergence threshold.',\n",
       "        'Set the maximum number of iterations and convergence thresholds.',\n",
       "        'The maximum number of iterations and convergence threshold is set.',\n",
       "        'The maximum number of iterations should be set.'],\n",
       "       ['Continue until convergence or the maximum iteration is reached.',\n",
       "        'Continue until either convergence or the maximum iteration is reached.',\n",
       "        'Continue until the maximum iteration is reached.',\n",
       "        'Continue until you reach the maximum iteration.',\n",
       "        'Continue until you reach the maximum iteration or convergence.',\n",
       "        'Continue until convergence or the maximum iteration has been reached.',\n",
       "        'Continue until convergence or the maximum iteration.',\n",
       "        'Continue until convergence or the maximum iteration reached.',\n",
       "        'Continue until the maximum iteration is reached or convergence is reached.',\n",
       "        'Continue until there is convergence or the maximum iteration.'],\n",
       "       ['The nearest cluster centroid will be assigned each data point.',\n",
       "        'The nearest cluster centroid should be assigned each data point.',\n",
       "        'Each data point should be assigned to the nearest cluster centroid.',\n",
       "        \"The nearest cluster centroid will be assigned each data point's location.\",\n",
       "        'Each data point should be assigned to a cluster centroid.',\n",
       "        'Each data point has to be assigned to the nearest cluster centroid.',\n",
       "        \"The nearest cluster centroid should be assigned each data point's location.\",\n",
       "        'Each data point should be assigned to the nearest cluster.',\n",
       "        'Each point should be assigned to the nearest cluster centroid.',\n",
       "        'Each data point should be assigned to a nearest cluster centroid.'],\n",
       "       ['Update cluster centroids.', 'The centroids have been updated.',\n",
       "        'Update centroids.', 'There is an update of cluster centroids.',\n",
       "        'The cluster centroids have been updated.',\n",
       "        'cluster centroids have been updated.',\n",
       "        'There is an update of centroids.',\n",
       "        'cluster centroids are being updated.',\n",
       "        'The centroids are updated.', 'Update cluster centroids'],\n",
       "       ['Check for convergence.', 'Check for convergence',\n",
       "        'Look for convergence.',\n",
       "        'Check to see if convergence is present.',\n",
       "        'Be sure to check for convergence.',\n",
       "        'Check to see if there is convergence.',\n",
       "        'Make sure to check for convergence.',\n",
       "        'Check to see if convergence is possible.',\n",
       "        'You should check for convergence.',\n",
       "        'Check to make sure convergence is present.'],\n",
       "       ['The final cluster centroids can be found in the quantum register.',\n",
       "        'Final cluster centroids can be found in the quantum register.',\n",
       "        'Final cluster centroids can be found in quantum register.',\n",
       "        'Final cluster centroids can be found in quantum registers.',\n",
       "        'The final cluster centroids are in the quantum register.',\n",
       "        'The final centroids are from the quantum register.',\n",
       "        'Final cluster centroids can be found from quantum registers.',\n",
       "        'Final cluster centroids can be found from quantum register.',\n",
       "        'The final cluster centroids can be found in quantum register.',\n",
       "        'The final cluster centroids can be found in quantum registers.'],\n",
       "       ['Classical representations can be obtained by code quantum cluster centroids.',\n",
       "        'Classical representations can be obtained with code quantum cluster centroids.',\n",
       "        'Classical representations can be obtained by decoding quantum cluster centroids.',\n",
       "        'Classical representations can be obtained using code quantum cluster centroids.',\n",
       "        'Classical representations can be obtained by coding quantum cluster centroids.',\n",
       "        'Classical representations can be obtained via code quantum cluster centroids.',\n",
       "        'Classical representations can be obtained through code quantum cluster centroids.',\n",
       "        'Classical representations are obtained by code quantum cluster centroids.',\n",
       "        'Code quantum cluster centroids to get classical representations.',\n",
       "        'Classical representations can be obtained by code quantum centroids.'],\n",
       "       ['Evaluate clustering quality using metrics.',\n",
       "        'Use metrics such as within-cluster sum of squares to evaluate clustering quality.',\n",
       "        'Evaluate clustering quality by using metrics.',\n",
       "        'Evaluate clustering quality with metrics such as within-cluster sum of squares.',\n",
       "        'Using metrics such as within-cluster sum of squares, evaluate clustering quality.',\n",
       "        'Use metrics such as the within-cluster sum of squares to evaluate clustering quality.',\n",
       "        'Evaluate clustering quality with metrics such as within-cluster sum of squares',\n",
       "        'Using metrics such as within-cluster sum of squares, you can evaluate clustering quality.',\n",
       "        'Evaluate clustering quality with metrics such as the within-cluster sum of squares.',\n",
       "        'Use metrics such as within-cluster sum of squares to evaluate clustering.'],\n",
       "       ['The final cluster centroids and evaluation results should be output.',\n",
       "        'Final cluster centroids and evaluation results should be output.',\n",
       "        'The final cluster centroids and evaluation results are to be output.',\n",
       "        'The final centroids and evaluation results should be output.',\n",
       "        'The final cluster centroids and evaluation results can be output.',\n",
       "        'The evaluation results and final cluster centroids should be output.',\n",
       "        'Evaluate the final cluster centroids.',\n",
       "        'The final cluster centroids and evaluation results need to be output.',\n",
       "        'The final clusters and evaluation results should be output.',\n",
       "        'The evaluation results should be output.']], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creaye a 2d array of size df list with 10 columns\n",
    "response = np.empty((len(df_list), 10), dtype=object)\n",
    "\n",
    "idx = 0\n",
    "for i in df_list:\n",
    "    context = i\n",
    "    num_return_sequences = 10\n",
    "    num_beams = 10\n",
    "    response[idx]=get_response(context, num_beams)\n",
    "    idx = idx + 1\n",
    "\n",
    "#get_response(context, num_return_sequences)\n",
    "#context = \"Initialize quantum registers to represent data points and cluster centroids.\"\n",
    "\n",
    "#val = get_response(context, num_return_sequences)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert response to csv file\n",
    "df_response = pd.DataFrame(response)\n",
    "df_response.to_csv('response.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mval\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lavenshtein distance between two strings   \n",
    "def lev(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    if s[-1] == t[-1]:\n",
    "        cost = 0\n",
    "    else:\n",
    "        cost = 1\n",
    "       \n",
    "    res = min([lev(s[:-1], t)+1,\n",
    "               lev(s, t[:-1])+1, \n",
    "               lev(s[:-1], t[:-1]) + cost])\n",
    "    \n",
    "\n",
    "    \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def similarity_score(s1, s2):\n",
    "    value = editdistance.eval(s1, s2)\n",
    "    return 1 - value / max(len(s1), len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'editdistance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimilarity_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(val)\n",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36msimilarity_score\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_score\u001b[39m(s1, s2):\n\u001b[0;32m----> 2\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43meditdistance\u001b[49m\u001b[38;5;241m.\u001b[39meval(s1, s2)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m value \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s1), \u001b[38;5;28mlen\u001b[39m(s2))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'editdistance' is not defined"
     ]
    }
   ],
   "source": [
    "similarity_score(context,val[0])\n",
    "len(val)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26315789473684215, 0.26315789473684215, 0.2763157894736842, 0.25, 0.25, 0.25, 0.3157894736842105, 0.23684210526315785, 0.3157894736842105, 0.23684210526315785]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.31578947, 8.        ],\n",
       "       [0.31578947, 6.        ],\n",
       "       [0.27631579, 2.        ],\n",
       "       [0.26315789, 1.        ],\n",
       "       [0.26315789, 0.        ],\n",
       "       [0.25      , 5.        ],\n",
       "       [0.25      , 4.        ],\n",
       "       [0.25      , 3.        ],\n",
       "       [0.23684211, 9.        ],\n",
       "       [0.23684211, 7.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = []\n",
    "\n",
    "for i in range(len(val)):\n",
    "    #create an aaray to store the index and similarity score\n",
    "  \n",
    "    sim.append(similarity_score(context,val[i]))\n",
    "print(sim)\n",
    "#convert sim to 2d array with index and similarity score and add index\n",
    "\n",
    "sim = np.array(sim)\n",
    "sim = sim.reshape(-1,1)\n",
    "sim = np.hstack((sim, np.arange(len(sim)).reshape(-1,1)))\n",
    "sim = sim[sim[:,0].argsort()[::-1]]\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the similarity score greater than 0.5\n",
    "sim = sim[sim[:,0]>0.9]\n",
    "sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
