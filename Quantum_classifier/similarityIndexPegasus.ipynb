{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importing necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# Define the model name and torch device\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Setting and Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optimization Settings: Generate code to add a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enhanced GPU Utilization: Write a function tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Augmentation: Provide code to implement d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Error Handling in Dataset Loading: Create erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quantum Circuit Parameter Tuning: Suggest code...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Setting and Description\n",
       "0  Optimization Settings: Generate code to add a ...\n",
       "1  Enhanced GPU Utilization: Write a function tha...\n",
       "2  Data Augmentation: Provide code to implement d...\n",
       "3  Error Handling in Dataset Loading: Create erro...\n",
       "4  Quantum Circuit Parameter Tuning: Suggest code..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"llm_strycture.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Optimization Settings: Generate code to add a learning rate scheduler to the optimizer in the Quantum Hybrid Neural Network to improve training efficiency.',\n",
       " 'Enhanced GPU Utilization: Write a function that ensures the HybridNet model and all tensors are moved to GPU if available, optimizing memory and computation speed.',\n",
       " 'Data Augmentation: Provide code to implement data augmentation in the DatasetHandler class for the training dataset to enhance model generalizability.',\n",
       " 'Error Handling in Dataset Loading: Create error handling in the DatasetHandler class for scenarios where data paths or labels cannot be correctly loaded or parsed.',\n",
       " 'Quantum Circuit Parameter Tuning: Suggest code modifications to allow dynamic adjustment of quantum circuit parameters such as the number of qubits and layers based on dataset features.',\n",
       " 'Real-time Training Metrics: Generate code for real-time visualization of training loss and validation accuracy during each epoch using matplotlib or another plotting library.',\n",
       " 'Checkpoint Enhancements: Improve the checkpoint saving mechanism to include more state information, such as the validation loss and the learning rate, and generate code for automatic recovery from the last best state after a failure.',\n",
       " 'Advanced Model Evaluation: Write code to perform more comprehensive model evaluations after training, including precision-recall curves and ROC curves for each class.',\n",
       " 'Quantum Layer Expansion: Propose a method to integrate additional quantum layers into the HybridNet model, and generate corresponding PyTorch-compatible quantum circuit code.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i want to iterate all the elements of df to list\n",
    "df_list = df[\"Setting and Description\"].values.tolist()\n",
    "df_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/adarshgowdaa/pegasus-paraphrase/blob/main/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text, num_return_sequences):\n",
    "    batch = tokenizer.prepare_seq2seq_batch(\n",
    "        [input_text], truncation=True, padding='longest', max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch, max_length=60, num_beams=10,\n",
    "                                num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4047: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4047: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['Generate code to add a learning rate scheduler to the optimizer to improve training efficiency.',\n",
       "        'Generate code to add a learning rate scheduler to the optimizer to improve training efficiency',\n",
       "        'Generate code to add a learning rate scheduler to the optimizer in the quantum hybrid neural network to improve training efficiency.',\n",
       "        'Adding a learning rate scheduler to the optimizer will improve training efficiency.',\n",
       "        'Generate code to add a learning rate scheduler to the optimizer in the quantum hybrid neural network to improve training efficiency',\n",
       "        'Generate code to add a learning rate scheduler to the optimizer in the quantum hybrid neural network.',\n",
       "        'To improve training efficiency, add a learning rate scheduler to the optimizer.',\n",
       "        'Generate code to add a learning rate scheduler to the optimizer in the quantum hybrid Neural Network to improve training efficiency.',\n",
       "        'Adding a learning rate scheduler to the optimizer in the quantum hybrid neural network will improve training efficiency.',\n",
       "        'Generate code to add a learning rate scheduler to the optimizer.'],\n",
       "       ['If available, write a function that ensures the hybridNet model and all tensors are moved to the graphics card.',\n",
       "        'If available, write a function that will ensure the hybridNet model and all tensors are moved to the graphics card.',\n",
       "        'If available, write a function that will ensure the hybridNet model and all tensors are moved to theGPU.',\n",
       "        'If available, write a function that will ensure the hybridNet model and all tensors are moved to the GPUs.',\n",
       "        'If available, write a function that will ensure the hybridNet model and all the tensors are moved to the graphics card.',\n",
       "        'If available, write a function that will ensure the hybridNet model and all the tensors are moved to theGPU.',\n",
       "        'If available, write a function that will ensure the hybridNet model and all the tensors are moved to the GPUs.',\n",
       "        'If available, write a function that will ensure that the hybridNet model and all the tensors are moved to theGPU.',\n",
       "        'If available, write a function that will ensure that the hybridNet model and all tensors are moved to theGPU.',\n",
       "        'If available, write a function that will ensure that the hybridNet model and all the tensors are moved to the graphics card.'],\n",
       "       ['Data augmentation can be accomplished by providing code to implement data augmentation in the DatasetHandler class.',\n",
       "        'Data augmentation can be done by providing code to implement data augmentation in the DatasetHandler class.',\n",
       "        'Data augmentation can be accomplished by providing code to implement data augmentation in the Dataset handler class.',\n",
       "        'Data augmentation involves providing code to implement data augmentation in the DatasetHandler class.',\n",
       "        'Data augmentation can be done by providing code to implement data augmentation in the Dataset handler class.',\n",
       "        'Data augmentation requires code to implement data augmentation in the DatasetHandler class.',\n",
       "        'Code to implement data augmentation in the DatasetHandler class for the training dataset to enhance model generalizability.',\n",
       "        'Code to implement data augmentation in the DatasetHandler class for the training dataset to enhance model generalizability',\n",
       "        'Data augmentation is the act of adding data to a training dataset.',\n",
       "        'Data augmentation can be accomplished by providing code to implement it in the DatasetHandler class.'],\n",
       "       ['There are scenarios where data paths or labels cannot be correctly loaded or parsed.',\n",
       "        \"When data paths or labels can't be correctly loaded or parsed, create error handling in the DatasetHandler class.\",\n",
       "        'When data paths or labels cannot be correctly loaded or parsed, create error handling in the DatasetHandler class.',\n",
       "        \"When data paths or labels can't be correctly loaded or parsed, there's an error handling class for that.\",\n",
       "        \"If data paths or labels can't be correctly loaded or parsed, create error handling in the DatasetHandler class.\",\n",
       "        \"When data paths or labels can't be correctly loaded or parsed, you can create error handling in the DatasetHandler class.\",\n",
       "        \"When data paths or labels can't be correctly loaded or parsed, there's an error handling class for it.\",\n",
       "        \"If data paths or labels can't be correctly loaded or parsed, you can create error handling in the DatasetHandler class.\",\n",
       "        \"When data paths or labels can't be correctly loaded or parsed, create an error handling class in the DatasetHandler class.\",\n",
       "        \"When data paths or labels can't be correctly loaded or parsed, there's an error handling class that can be created.\"],\n",
       "       ['Suggest code modifications to allow dynamic adjustment of quantum circuit parameters such as the number of qubits and layers based on dataset features.',\n",
       "        'Suggest code modifications to allow dynamic adjustment of quantum circuit parameters such as the number of qubits and layers.',\n",
       "        'Suggest code modifications to allow dynamic adjustment of quantum circuit parameters, such as the number of qubits and layers.',\n",
       "        'Suggest code modifications to allow dynamic adjustment of quantum circuit parameters, such as the number of qubits and layers, based on dataset features.',\n",
       "        'Suggest code modifications to allow for dynamic adjustment of quantum circuit parameters, such as the number of qubits and layers.',\n",
       "        'Suggest code modifications to allow for dynamic adjustment of quantum circuit parameters such as the number of qubits and layers.',\n",
       "        'Suggest code modifications to allow for dynamic adjustment of quantum circuit parameters such as the number of qubits and layers based on dataset features.',\n",
       "        'Suggest code modifications to allow dynamic adjustment of quantum circuit parameters, such as the number of qubits and layers based on dataset features.',\n",
       "        'Suggest code modifications to allow for dynamic adjustment of quantum circuit parameters, such as the number of qubits and layers, based on dataset features.',\n",
       "        'Suggest code modifications to allow for dynamic adjustment of quantum circuit parameters, such as the number of qubits and layers based on dataset features.'],\n",
       "       ['Generate code for visualization of training loss and validation accuracy using matplotlib or another library.',\n",
       "        'Generate code for real-time visualization of training loss and validation accuracy using matplotlib or another library.',\n",
       "        'Generate code for visualization of training loss and validation accuracy using matplotlib.',\n",
       "        'Generate code for visualization of training loss and validation accuracy using matplotlib or another plotting library.',\n",
       "        'Generate code for real-time visualization of training loss and validation accuracy using matplotlib or another plotting library.',\n",
       "        'Matplotlib or another plotting library can be used to generate code for real-time visualization of training loss and validation accuracy.',\n",
       "        'Generate code for real-time visualization of training loss and validation accuracy using matplotlib.',\n",
       "        'Generate code for visualization of training loss and validation accuracy using matplotlib or another plot library.',\n",
       "        'Generate code for real-time visualization of training loss and validation accuracy using matplotlib or another plot library.',\n",
       "        'Generate code for real-time visualization of training loss and validation accuracy during each epoch using matplotlib or another plotting library.'],\n",
       "       ['Improve the checkpoint saving mechanism to include more state information, such as the validation loss and the learning rate, and generate code for automatic recovery from the last best state after a failure.',\n",
       "        'Improve the checkpoint saving mechanism to include more state information, such as the validation loss and learning rate, and generate code for automatic recovery from the last best state after a failure.',\n",
       "        'The checkpoint saving mechanism should be improved to include more state information, such as the validation loss and learning rate, and generate code for automatic recovery from the last best state after a failure.',\n",
       "        'The checkpoint saving mechanism should be improved to include more state information, such as the validation loss and the learning rate, and generate code for automatic recovery from the last best state after a failure.',\n",
       "        'Improve the checkpoint saving mechanism to include more state information, such as the validation loss and the learning rate, and generate code for automatic recovery from the last best state after a failure',\n",
       "        'Improve the checkpoint saving mechanism to include more state information, such as the validation loss and learning rate, and generate code for automatic recovery from the last best state after a failure',\n",
       "        'The checkpoint saving mechanism can be improved to include more state information, such as the validation loss and learning rate, and generate code for automatic recovery from the last best state after a failure.',\n",
       "        'Improve the checkpoint saving mechanism to include more state information, such as the validation loss and the learning rate, and generate code for automatic recovery after a failure.',\n",
       "        'The checkpoint saving mechanism should be improved to include more state information, such as the validation loss and learning rate, and generate code for automatic recovery after a failure.',\n",
       "        'The checkpoint saving mechanism can be improved to include more state information, such as the validation loss and the learning rate, and generate code for automatic recovery from the last best state after a failure.'],\n",
       "       ['After training, write code to perform more comprehensive model evaluations, including precision-recall curves and ROC curves.',\n",
       "        'After training, write code to perform more comprehensive model evaluations, including precision-recall curves and ROC curves for each class.',\n",
       "        'Code can be written to perform more comprehensive model evaluations after training, including precision-recall curves and ROC curves.',\n",
       "        'After training, write code to perform more comprehensive model evaluations, which include precision-recall curves and ROC curves.',\n",
       "        'After training, write code to perform more comprehensive model evaluations, which include precision-recall curves and ROC curves for each class.',\n",
       "        'After training, write code to perform more comprehensive model evaluations, such as precision-recall curves and ROC curves.',\n",
       "        'After training, write code to perform more comprehensive model evaluations, including precision-recall curves and ROC curves, for each class.',\n",
       "        'Code can be written to perform more comprehensive model evaluations after training, including precision-recall curves and ROC curves for each class.',\n",
       "        'Code should be written to perform more comprehensive model evaluations after training, including precision-recall curves and ROC curves.',\n",
       "        'After training, write code to perform more comprehensive model evaluations, including precision-recall curves for each class.'],\n",
       "       ['Propose a method to integrate additional quantum layers into the hybridNet model and generate corresponding PyTorch compatible quantum circuit code.',\n",
       "        'Propose a method to integrate additional quantum layers into the hybridnet model and generate corresponding PyTorch compatible quantum circuit code.',\n",
       "        'Propose a method to integrate additional quantum layers into the model and generate corresponding PyTorch compatible quantum circuit code.',\n",
       "        'A method to integrate additional quantum layers into the hybrid net model is proposed.',\n",
       "        'A method to integrate additional quantum layers into the hybridnet model is proposed.',\n",
       "        'Propose a method to integrate additional quantum layers into the hybrid net model and generate corresponding PyTorch compatible quantum circuit code.',\n",
       "        'Propose a method to integrate additional quantum layers into the hybridnet model, and generate corresponding PyTorch compatible quantum circuit code.',\n",
       "        'Propose a method to integrate additional quantum layers into the hybrid net model and generate corresponding py torch compatible quantum circuit code.',\n",
       "        'Propose a method to integrate additional quantum layers into the hybrid net model and generate corresponding pytorch compatible quantum circuit code.',\n",
       "        'Propose a method to integrate additional quantum layers into the hybridnet model and generate corresponding PyTorch compatible quantum circuit code']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creaye a 2d array of size df list with 10 columns\n",
    "response = np.empty((len(df_list), 10), dtype=object)\n",
    "\n",
    "idx = 0\n",
    "for i in df_list:\n",
    "    context = i\n",
    "    num_return_sequences = 10\n",
    "    num_beams = 10\n",
    "    response[idx]=get_response(context, num_beams)\n",
    "    idx = idx + 1\n",
    "\n",
    "#get_response(context, num_return_sequences)\n",
    "#context = \"Initialize quantum registers to represent data points and cluster centroids.\"\n",
    "\n",
    "#val = get_response(context, num_return_sequences)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert response to csv file\n",
    "df_response = pd.DataFrame(response)\n",
    "df_response.to_csv('generated_prompts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lavenshtein distance between two strings   \n",
    "def lev(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    if s[-1] == t[-1]:\n",
    "        cost = 0\n",
    "    else:\n",
    "        cost = 1\n",
    "       \n",
    "    res = min([lev(s[:-1], t)+1,\n",
    "               lev(s, t[:-1])+1, \n",
    "               lev(s[:-1], t[:-1]) + cost])\n",
    "            \n",
    "    \n",
    "\n",
    "    \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def similarity_score(s1, s2):\n",
    "    value = editdistance.eval(s1, s2)\n",
    "    return 1 - value / max(len(s1), len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m similarity_score(context,\u001b[43mval\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(val)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "similarity_score(context,val[0])\n",
    "len(val)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sim \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mval\u001b[49m)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#create an aaray to store the index and similarity score\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     sim\u001b[38;5;241m.\u001b[39mappend(similarity_score(context,val[i]))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(sim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "sim = []\n",
    "\n",
    "for i in range(len(val)):\n",
    "    #create an aaray to store the index and similarity score\n",
    "  \n",
    "    sim.append(similarity_score(context,val[i]))\n",
    "print(sim)\n",
    "#convert sim to 2d array with index and similarity score and add index\n",
    "\n",
    "sim = np.array(sim)\n",
    "sim = sim.reshape(-1,1)\n",
    "sim = np.hstack((sim, np.arange(len(sim)).reshape(-1,1)))\n",
    "sim = sim[sim[:,0].argsort()[::-1]]\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the similarity score greater than 0.5\n",
    "sim = sim[sim[:,0]>0.9]\n",
    "sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
